{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you've loaded the dataset into a DataFrame (replace `data.csv` with the actual file path or URL)\n",
    "df = pd.read_csv('../dataset/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['id', 'sourceURLs', 'imageURLs', 'ean', 'upc', 'manufacturerNumber', 'keys']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prices.availability prices.condition prices.currency  \\\n",
      "0                 Yes              New             USD   \n",
      "1                 Yes              New             USD   \n",
      "2                 Yes              New             USD   \n",
      "3                 Yes              New             USD   \n",
      "4     More on the Way              New             USD   \n",
      "\n",
      "                                     prices.dateSeen  prices.isSale  \\\n",
      "0          2017-05-10T20:00:00Z,2017-05-09T15:00:00Z            NaN   \n",
      "1  2017-10-10T02:00:00Z,2017-08-12T03:00:00Z,2017...            NaN   \n",
      "2  2017-10-10T19:00:00Z,2017-09-12T14:00:00Z,2017...            NaN   \n",
      "3  2017-09-08T05:00:00Z,2017-09-18T13:00:00Z,2017...            NaN   \n",
      "4                               2017-12-05T13:00:00Z            NaN   \n",
      "\n",
      "    prices.merchant                                   prices.shipping  \\\n",
      "0       Bestbuy.com                                               NaN   \n",
      "1       Bestbuy.com                                               NaN   \n",
      "2       Bestbuy.com                                               NaN   \n",
      "3       Bestbuy.com                                               NaN   \n",
      "4  bhphotovideo.com  Free Expedited Shipping for most orders over $49   \n",
      "\n",
      "                                   prices.sourceURLs       asins  \\\n",
      "0  http://www.bestbuy.com/site/products/7100293.p...  B00I9HD8PK   \n",
      "1  https://www.bestbuy.com/site/lenovo-100s-14ibr...  B06ZY63J8H   \n",
      "2  https://www.bestbuy.com/site/house-of-marley-s...  B00G3P9UMU   \n",
      "3  https://www.bestbuy.com/site/products/6311012....  B00TTWZFFA   \n",
      "4  https://www.bhphotovideo.com/c/product/1105014...  B00MHPAF38   \n",
      "\n",
      "             brand  ...           dateUpdated     manufacturer  \\\n",
      "0    Grace Digital  ...  2018-02-13T19:46:08Z         Ecoxgear   \n",
      "1           Lenovo  ...  2018-01-30T06:06:16Z              NaN   \n",
      "2  House of Marley  ...  2018-05-16T20:23:54Z  House Of Marley   \n",
      "3             Sony  ...  2018-01-30T03:06:18Z             Sony   \n",
      "4             Sony  ...  2018-07-26T15:58:38Z              NaN   \n",
      "\n",
      "                                                name primaryCategories weight  \\\n",
      "0                EcoXGear Ecostone Bluetooth Speaker       Electronics    NaN   \n",
      "1  Lenovo - 100S-14IBR 14 Laptop - Intel Celeron ...       Electronics    NaN   \n",
      "2       House of Marley Smile Jamaica In-Ear Earbuds       Electronics    NaN   \n",
      "3              Sony Ultra-Portable Bluetooth Speaker       Electronics    NaN   \n",
      "4  Alpha a5100 Mirrorless Digital Camera with 16-...       Electronics    NaN   \n",
      "\n",
      "    price  year_added  month_added  day_added  days_since_added  \n",
      "0   92.99        2015           11          1              3427  \n",
      "1  229.99        2017            3         13              2928  \n",
      "2   16.99        2014           10         28              3795  \n",
      "3   69.99        2015           11          6              3422  \n",
      "4  846.00        2017            7         18              2801  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# View the first few rows to understand its structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prices.availability', 'prices.condition', 'prices.currency',\n",
      "       'prices.dateSeen', 'prices.isSale', 'prices.merchant',\n",
      "       'prices.shipping', 'prices.sourceURLs', 'asins', 'brand', 'categories',\n",
      "       'dateAdded', 'dateUpdated', 'manufacturer', 'name', 'primaryCategories',\n",
      "       'weight', 'price', 'year_added', 'month_added', 'day_added',\n",
      "       'days_since_added'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names to ensure they match the ones you want to drop\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle 'prices.isSale' (convert 'TRUE'/'FALSE' to 1/0)\n",
    "df['prices.isSale'] = df['prices.isSale'].map({'TRUE': 1, 'FALSE': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'dateAdded' to timezone-naive if it's timezone-aware\n",
    "df['dateAdded'] = df['dateAdded'].dt.tz_localize(None)\n",
    "\n",
    "# Now calculate the 'days_since_added' column\n",
    "df['days_since_added'] = (pd.to_datetime('today') - df['dateAdded']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'dateAdded' to timezone-aware if it's not\n",
    "df['dateAdded'] = df['dateAdded'].dt.tz_localize('UTC', ambiguous='NaT')\n",
    "\n",
    "# Convert 'today' to a timezone-aware datetime object\n",
    "today = pd.to_datetime('today').tz_localize('UTC')\n",
    "\n",
    "# Now calculate the 'days_since_added' column\n",
    "df['days_since_added'] = (today - df['dateAdded']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle weight (ensure it's numeric)\n",
    "df['weight'] = pd.to_numeric(df['weight'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable: 'price' (you want to predict this)\n",
    "X = df.drop(columns=['price'])\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Standard Scaling to numerical features (like weight, days_since_added)\n",
    "numerical_cols = ['weight', 'days_since_added']\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline for numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numerical_cols),\n",
    "        # Add more transformations for other features (if needed)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a machine learning pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))  # Example model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 575.5965817290239\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model (example with RMSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4348, 5)\n",
      "X_test shape: (1088, 5)\n",
      "y_train shape: (4348,)\n",
      "y_test shape: (1088,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select only the required columns\n",
    "X = df[['weight', 'year_added', 'month_added', 'day_added', 'days_since_added']]\n",
    "y = df['price']\n",
    "\n",
    "# Train-test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the resulting sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 562.2273900297887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f'Random Forest RMSE: {rmse_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 562.62573090101\n",
      "R²: 0.4067512342757382\n"
     ]
    }
   ],
   "source": [
    "# Import the RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Calculate R² score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 562.62573090101\n",
      "R²: 0.4067512342757382\n",
      "MAE (Mean Absolute Error): 304.5838728312959\n",
      "MSE (Mean Squared Error): 316547.7130718957\n",
      "Explained Variance Score: 0.40795126263630166\n",
      "Max Error: 4269.253732803532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score, max_error\n",
    "\n",
    "# Calculate MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Explained Variance Score\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Max Error\n",
    "max_err = max_error(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "print(f\"Explained Variance Score: {evs}\")\n",
    "print(f\"Max Error: {max_err}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 562.62573090101\n",
      "R²: 0.4067512342757382\n",
      "MAE (Mean Absolute Error): 304.5838728312959\n",
      "MSE (Mean Squared Error): 316547.7130718957\n",
      "Explained Variance Score: 0.40795126263630166\n",
      "Max Error: 4269.253732803532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score, max_error\n",
    "\n",
    "# Calculate MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Explained Variance Score\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Max Error\n",
    "max_err = max_error(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "print(f\"Explained Variance Score: {evs}\")\n",
    "print(f\"Max Error: {max_err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate these matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 562.62573090101\n",
      "R²: 0.4067512342757382\n",
      "Adjusted R²: 0.4040097889627796\n",
      "MAE (Mean Absolute Error): 304.5838728312959\n",
      "MSE (Mean Squared Error): 316547.7130718957\n",
      "Explained Variance Score: 0.40795126263630166\n",
      "Max Error: 4269.253732803532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score, max_error\n",
    "\n",
    "# Assuming y_test and y_pred are already defined:\n",
    "# y_test: true target values\n",
    "# y_pred: predicted values by the model\n",
    "\n",
    "\n",
    "# R-squared (R²)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Max Error\n",
    "max_err = max_error(y_test, y_pred)\n",
    "\n",
    "# Adjusted R² (Optional but useful in multiple regression)\n",
    "n = len(y_test)  # number of samples\n",
    "p = X_test.shape[1]  # number of predictors\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Displaying all evaluation metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"Adjusted R²: {adj_r2}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "print(f\"Explained Variance Score: {evs}\")\n",
    "print(f\"Max Error: {max_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
